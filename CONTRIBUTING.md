## Contributing Instructions

Pull the project.

```sh
git clone https://github.com/pganalyze/collector
```

Make sure you have `gcc` installed and in your $PATH: parts of the collector's
dependencies rely on [cgo](https://pkg.go.dev/cmd/cgo) and will be skipped if
a C compiler is not available, causing the collector build to fail.

### Setup

The dependencies are stored in the `vendor` folder, so no installation is needed.

### Updating dependencies

```sh
go get github.com/shirou/gopsutil@latest # updates the version requirement
make vendor                              # updates the vendored code
```

### Compiling and running tests

To compile the collector and helper binaries:

```sh
make build
```

After building the collector you can find the binary in the repository folder:

```sh
./pganalyze-collector --help
```

To run the unit tests:

```sh
make test
```

To run the integration tests:

```sh
make integration_test
```

Note the integration tests require Docker, and will take a while to run through.

#### Test receiving Postgres logs over syslog

The ability to receive Postgres logs over syslog is not covered by
automated tests. To test this manually, you'll need to relay the
Postgres logs through a syslog daemon.

Here's one way to do that (assuming a locally running Postgres on a
Debian/Ubuntu system):

 - `sudo apt install rsyslog`
 - edit your Postgres config file and set `log_destination` to `syslog`
 - add the following rsyslog configuration file at `/etc/rsyslog.d/51-postgres.conf`:
   ```
   if $programname == 'postgres' then {
     *.* action(
       type="omfwd"
       StreamDriver="ptcp"
       StreamDriverMode="0"
       template="RSYSLOG_SyslogProtocol23Format"
       target="localhost" port="5514" protocol="tcp"
       action.resumeRetryCount="100"
       queue.type="linkedList" queue.size="10000"
     )
   }
   ```
   you can pick another port if 5514 is not available
 - `sudo service rsyslog restart`
 - update your local collector configuration to monitor your local Postgres
 - update the configuration to add `db_log_syslog_server = 0.0.0.0:5514`
   (or whatever port you selected above)
 - start the collector
 - run `SELECT pg_reload_conf()` in Postgres

The collector should now be receiving Postgres logs via rsyslog.

### Build the Helm Docs

The Helm chart [`README.md` file](contrib/helm/pganalyze-collector/README.md) is
generated by [helm-docs](https://github.com/norwoodj/helm-docs).
To ensure that the documentation remains up-to-date, regenerate the `README.md`
file using the `helm-docs` command whenever you make changes to the Helm chart
or prior to making a new release.

You can either [install `helm-docs` locally](https://github.com/norwoodj/helm-docs?tab=readme-ov-file#installation),
or run using Docker:

```sh
$ docker run --rm --volume "$(pwd):/helm-docs" -u "$(id -u)" jnorwood/helm-docs:latest
time="2024-04-26T02:01:07Z" level=info msg="Found Chart directories [contrib/helm/pganalyze-collector]"
time="2024-04-26T02:01:07Z" level=info msg="Generating README Documentation for chart contrib/helm/pganalyze-collector
```

### Release

1. Create a PR to update the version numbers, CHANGELOG.md, and Helm Docs (see above)
2. Once PR is merged, create a new tag `git tag v0.x.y`, then push it `git push origin v0.x.y`
3. Once a new tag is pushed, GitHub Action Release will be kicked and create a new release (this will take about 2 hours, due to the package build and test)
4. Modify the newly created release's description to match to CHANGELOG.md
5. Release docker images using `make docker_release` (this requires access to the Quay.io push key, as well as "docker buildx" with QEMU emulation support, see below)
6. Sign and release packages using `make -C packages repo` (this requires access to the Keybase GPG key)

To run step 5 from an Ubuntu 24.04 VM, do the following:
(use the c8i.2xlarge instance or higher, takes ~10+ minutes)

```
# Get password (entered interactively) from Quay.io
# (under the robot accounts of the pganalyze organization)
sudo docker login -u="pganalyze+push" quay.io

# Add Docker's official GPG key:
sudo apt-get update && \
sudo apt-get install -y ca-certificates curl gnupg && \
sudo install -m 0755 -d /etc/apt/keyrings && \
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg && \
sudo chmod a+r /etc/apt/keyrings/docker.gpg

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null && \
sudo apt-get update && \
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin

# Add support for ARM emulation and build
sudo apt-get install -y qemu-user-static binfmt-support make && \
git clone https://github.com/pganalyze/collector.git && \
cd collector && \
sudo make docker_release
```

### Updating wait event types and names

Postgres can change wait event names or add new wait event types, which are
shown in `pg_stat_activity`. While the collector sends wait event names and wait
event types as string values inside the compact snapshot, we define the wait
event related definitions in the protobuf directory.

These files are used on the pganalyze app side, to map the string type and name
to a protobuf enum value (e.g. `111`), which is then stored in the pganalyze
database to reduce storage space. Later on, this value is mapped back to the
original name when displaying it in the client/UI.

* `protobuf/compact_activity_snapshot.proto`: defines enums of `WaitEventType` and `WaitEvent`
* `protobuf/mappings/wait_event_type.json`: defines a mapping of wait event types to enum values
* `protobuf/mappings/wait_event.json`: defines a mapping of wait event names to enum values

To update the wait event names, first check the history of [wait_event_names.txt](https://github.com/postgres/postgres/blob/master/src/backend/utils/activity/wait_event_names.txt)
to find out what has been introduced/removed/renamed/moved to a different type.

**Newly introduced names**

1. Add a new name to `protobuf/compact_activity_snapshot.proto` under the corresponding type
   - Be creative if the available numbers are running out, but do not reuse an enum value
   - `WaitEventType: LWLock` has two subcategories, `LWLOCK` and `LWTRANCHE`
   - They were previously different types. When adding a new name under these types,
     carefully check which category it belongs to
   - In the comment, add `(PG1X+)` at the end to indicate when it was introduced
2. Add a mapping to `protobuf/mappings/wait_event.json`
   - This name should match what is shown in `pg_stat_activity`
   - For most names, PascalCase should be used (except `LWLock` or `Lock` type names)

**Removed names**

1. Add `(removed in XX)` to the comment of `protobuf/compact_activity_snapshot.proto`
2. No changes to `protobuf/mappings/wait_event.json` (will still be used for older versions)

**Renamed names**

If the name changed significantly, or the type is moved, it can be treated as a
completely new name and the "Newly introduced names" steps can be followed.
Below is the example of such renames:

```
    WAIT_EVENT_RELATION_MAP_SYNC = 932; // RelationMapSync (renamed to RelationMapReplace)
    WAIT_EVENT_RELATION_MAP_REPLACE = 978; // RelationMapReplace (PG17+, renamed from RelationMapSync)
```

This section covers cases where the rename is minimal, like from "Hash/Batch/Allocating" to "HashBatchAllocate".

1. Add a new name to the comment in `protobuf/compact_activity_snapshot.proto`
2. Add a mapping to `protobuf/mappings/wait_event.json`
   - The key is a new name, and the value is the existing enum value
   - Make sure to add this _below the old name line_ (and do not remove the old name)
   - When we map back from the enum value to the name on the pganalyze app side,
     we will use the newer name (the ones defined later on in the JSON)

**Names moved to a different type**

When a name is moved to a different type, we do not need to create a new enum,
since the event type is sent separately from the event name and the existing
enum value can still be used.

1. Add a `(moved to NEWTYPE in PG1X)` comment to `protobuf/compact_activity_snapshot.proto`
2. No changes to `protobuf/mappings/wait_event.json`
